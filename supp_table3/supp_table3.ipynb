{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b801470",
   "metadata": {},
   "source": [
    "README:  \n",
    "PhaNNs expandedDB downloaded (https://phanns.com/download/expandedDB.tgz) on 01172023  \n",
    "all_sequence_ids_to_vectors_dict.pkl is a dictionary that contains protbert_bfd embeddings for the PhaNNs sequences and is available for download from the KellyLab GCP in the viral_protein_family_plm_embeddings bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25532ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e7d1a",
   "metadata": {},
   "source": [
    "# collecting and organizing train and test sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3392a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faa(path: str):\n",
    "    seqs = []\n",
    "    seq = []\n",
    "\n",
    "    with(open(path)) as file:\n",
    "        for line in file:\n",
    "            line = line.rstrip()\n",
    "            if line.startswith('>'):\n",
    "                if len(seq) > 0:\n",
    "                    seqs.append( ''.join(seq))\n",
    "                    seq = []\n",
    "            else:\n",
    "                seq.append(line)\n",
    "    seqs.append(''.join(seq))\n",
    "    return seqs\n",
    "\n",
    "def get_faa_identifier(path: str):\n",
    "    idents = []\n",
    "    with(open(path)) as file:\n",
    "        for line in file:\n",
    "            line = line.rstrip()\n",
    "            if line.startswith('>'):\n",
    "                idents.append(line)\n",
    "    return idents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c52fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = [\n",
    "'HTJ',\n",
    "'portal',\n",
    "'major_tail',\n",
    "'major_capsid',\n",
    "'minor_tail',\n",
    "'baseplate',\n",
    "'collar',\n",
    "'shaft',\n",
    "'other',\n",
    "'tail_fiber',\n",
    "'minor_capsid'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'expandedDB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dict = {}\n",
    "testing_dict = {}\n",
    "\n",
    "for d in cats:\n",
    "    idents_train = []\n",
    "    idents_test = []\n",
    "    files = [x for x in os.listdir(data_dir) if d in x]\n",
    "    for f in files:\n",
    "        if f.startswith('.'):\n",
    "            continue\n",
    "        if f.split('_')[0] == '11':\n",
    "            idents_test.append(get_faa_identifier('{0}/{1}' ''.format(data_dir,f)))\n",
    "        else:\n",
    "            idents_train.append(get_faa_identifier('{0}/{1}' ''.format(data_dir,f)))\n",
    "    \n",
    "    idents_train = [l for ll in idents_train for l in ll]\n",
    "    idents_test = [l for ll in idents_test for l in ll]\n",
    "    \n",
    "    print(d)\n",
    "    print('total number of sequences in training 10 sets: {0}' ''.format(len(idents_train)))\n",
    "    print('total number of sequences in testing 1 sets: {0}' ''.format(len(idents_test)))\n",
    "    print('\\n')\n",
    "    \n",
    "    training_dict[d] = idents_train\n",
    "    testing_dict[d] = idents_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16b35ac",
   "metadata": {},
   "source": [
    "# load phann sequences plm embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce2d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_to_vectors = pickle.load(open('all_sequence_ids_to_vectors_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5b4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvp_training_vecs = []\n",
    "other_training_vecs = []\n",
    "for k in training_dict.keys():\n",
    "    if k != 'other':\n",
    "        pvp_training_vecs.append([seqs_to_vectors[s] for s in training_dict[k]])\n",
    "    else:\n",
    "        other_training_vecs.append([seqs_to_vectors[s] for s in training_dict[k]])\n",
    "\n",
    "pvp_training_vecs = [v for l in pvp_training_vecs for v in l]\n",
    "other_training_vecs = [v for l in other_training_vecs for v in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b630dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(other_training_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3953e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pvp_training_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a68b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvp_testing_vecs = []\n",
    "other_testing_vecs = []\n",
    "for k in testing_dict.keys():\n",
    "    if k != 'other':\n",
    "        pvp_testing_vecs.append([seqs_to_vectors[s] for s in testing_dict[k]])\n",
    "    else:\n",
    "        other_testing_vecs.append([seqs_to_vectors[s] for s in testing_dict[k]])\n",
    "\n",
    "pvp_testing_vecs = [v for l in pvp_testing_vecs for v in l]\n",
    "other_testing_vecs = [v for l in other_testing_vecs for v in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1832a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(other_testing_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9ea8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pvp_testing_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit a label binarizer to the classes, need to have this done before splits to the categories are the same in each split\n",
    "cats = ['pvp', 'other']\n",
    "lb = LabelEncoder()\n",
    "cats = lb.fit_transform(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20bb099",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvp_training_label = ['pvp'] * len(pvp_training_vecs)\n",
    "other_training_label = ['other'] * len(other_training_vecs)\n",
    "\n",
    "pvp_testing_label = ['pvp'] * len(pvp_testing_vecs)\n",
    "other_testing_label = ['other'] * len(other_testing_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbcc8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_vecs = np.concatenate((pvp_training_vecs, other_training_vecs), axis=0)\n",
    "all_testing_vecs = np.concatenate((pvp_testing_vecs, other_testing_vecs), axis=0)\n",
    "\n",
    "all_training_labels = np.concatenate((pvp_training_label, other_training_label), axis=0)\n",
    "all_testing_labels = np.concatenate((pvp_testing_label, other_testing_label), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072af4d7",
   "metadata": {},
   "source": [
    "# FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dca4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = all_training_vecs\n",
    "testX = all_testing_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ebe577",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = lb.fit_transform(all_training_labels)\n",
    "trainY = to_categorical(trainY)\n",
    "\n",
    "testY = lb.fit_transform(all_testing_labels)\n",
    "testY = to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2db83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(1024,), activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, input_shape=(512,), activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, input_shape=(256,), activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(9, input_shape=(128,), activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557fa78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 5\n",
    "opt = Adam(0.00001)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "H = model.fit(trainX, trainY, epochs=n_epoch, batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d92470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed93e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fda346",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=[str(x) for x in lb.classes_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1d73e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: {0}' ''.format(precision_score(testY.argmax(axis=1), predictions.argmax(axis=1))))\n",
    "print('Recall: {0}' ''.format(recall_score(testY.argmax(axis=1), predictions.argmax(axis=1))))\n",
    "print('F1: {0}' ''.format(f1_score(testY.argmax(axis=1), predictions.argmax(axis=1))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
